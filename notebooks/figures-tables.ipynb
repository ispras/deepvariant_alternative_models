{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56a01579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy import stats\n",
    "from scipy.stats import t\n",
    "import numpy as np\n",
    "from matplotlib.patches import Patch\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdd89639",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['Inception_V3','EfficientNet_B3']\n",
    "models_features = {'Inception_V3':{'color':['#c6dcff']},'EfficientNet_B3':{'color':['#86cbd6']}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d598b7",
   "metadata": {},
   "source": [
    "# Keras models info (Figure 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "46766435",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/data/glusterfs/agurianova/architecture_change/notebooks/keras_model_info.csv', sep = ',')\n",
    "family_colors = {'Inception':'#c6dcff', 'EfficientNet':'#c2e5eb'}\n",
    "df['Color'] = df['Family'].map(family_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a1b5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(2.5, 2))\n",
    "\n",
    "bars = ax1.bar(\n",
    "    x=df['Model'],\n",
    "    height=df['Acc@1'],\n",
    "    color=df['Color'],\n",
    "    label=\"Top-1 accuracy\",\n",
    "    edgecolor='black',  # Border color\n",
    "    linewidth=1 \n",
    ")\n",
    "ax1.set_xlabel(\"Model\")\n",
    "ax1.set_ylabel(\"Top-1 accuracy (%)\", color='black')\n",
    "ax1.tick_params(axis='y', labelcolor='black')\n",
    "ax1.set_xticks(df['Model'])\n",
    "ax1.set_xticklabels(df['Model'], rotation=90)\n",
    "#ax1.set_ylim(0,100)\n",
    "\n",
    "inception_acc = df.loc[df['Model'] == 'Inception_V3', 'Acc@1'].values\n",
    "ax1.axhline(y=inception_acc, color='black', linestyle='--', linewidth=1, label='Inception_V3')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(\n",
    "    df['Model'],\n",
    "    df['Params'] ,\n",
    "    color='black',\n",
    "    marker='x',\n",
    "    linestyle='',\n",
    "    linewidth=1,\n",
    "    label=\"Parameters\"\n",
    ")\n",
    "ax2.set_ylabel(\"Parameters (Millions)\", color='black')\n",
    "ax2.tick_params(axis='y', labelcolor='black')\n",
    "\n",
    "# Add Time_GPU line\n",
    "ax3 = ax1.twinx()\n",
    "ax3.plot(\n",
    "    df['Model'],\n",
    "    df['Time_GPU'],\n",
    "    color='black',\n",
    "    marker='o',\n",
    "    linestyle='-',\n",
    "    linewidth=1,\n",
    "    label=\"GPU Time\",\n",
    "    alpha = 0.5\n",
    ")\n",
    "# Position the third y-axis on the right\n",
    "ax3.spines['right'].set_position(('outward', 40))\n",
    "ax3.set_ylabel(\"GPU Time (ms)\", color='black')\n",
    "ax3.tick_params(axis='y', labelcolor='black')\n",
    "\n",
    "legend_patches = [mpatches.Patch(color=color, label=label) for label, color in family_colors.items() if label in df['Family'].unique()]\n",
    "ax1.legend(handles=legend_patches, title=\"Family\", bbox_to_anchor=(1.55, 1), loc='upper left')\n",
    "ax2.legend(loc='upper left',bbox_to_anchor=(1.55, 0.5))\n",
    "ax3.legend(loc='upper left', bbox_to_anchor=(1.55, 0.27))\n",
    "\n",
    "plt.title(\"Performance on ImageNet\")\n",
    "#fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748ecf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_log(file_path, metric='f1_weighted', part='tune'):\n",
    "    parsed = []\n",
    "\n",
    "    model_type = None\n",
    "    opt = None\n",
    "    lr = None\n",
    "    trial = None\n",
    "\n",
    "    label = None\n",
    "\n",
    "    timestamp_pattern = r'\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2},\\d{3}'\n",
    "    first_timestamp = None\n",
    "    last_timestamp = None\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "\n",
    "            # model\n",
    "            if model_type is None:\n",
    "                m = re.search(r'model_type:\\s*([^\\s]+)', line)\n",
    "                if m:\n",
    "                    model_type = m.group(1)\n",
    "\n",
    "            # values\n",
    "            matches = re.findall(rf'{part}/{metric}(?:_\\d+)?=([\\d.e-]+),', line) #re.findall(rf'{part}/{metric}=([\\d.e-]+),', line)\n",
    "            if matches:\n",
    "                parsed.extend(map(float, matches))\n",
    "\n",
    "            # optimizer\n",
    "            if opt is None:\n",
    "                match = re.search(r'optimizer:\\s+([^\\s]+)', line) \n",
    "                if match:\n",
    "                    opt = match.group(1)\n",
    "\n",
    "            # lr\n",
    "            if lr is None:\n",
    "                match = re.search(r'learning_rate:\\s+([^\\s]+)', line)\n",
    "                if match:\n",
    "                    lr = float(match.group(1))    \n",
    "\n",
    "            # trial\n",
    "            if trial is None:\n",
    "                match = re.search(r'Optuna. Trial\\s+([\\d.e-]+)', line)     \n",
    "                if match:\n",
    "                    trial = match.group(1)\n",
    "\n",
    "            # time\n",
    "            match = re.search(timestamp_pattern, line)\n",
    "            if match:\n",
    "                ts_str = match.group(0)\n",
    "                ts = datetime.strptime(ts_str, '%Y-%m-%d %H:%M:%S,%f')\n",
    "                if first_timestamp is None:\n",
    "                    first_timestamp = ts\n",
    "                last_timestamp = ts     \n",
    "\n",
    "    present_points = [i for i in range(len(parsed)) if i not in (3, 8)] if part == 'tune' else range(len(parsed)) # skip intermediate validation checks\n",
    "    parsed = [parsed[i] for i in present_points]          \n",
    "\n",
    "    parsed_smoothed = []\n",
    "    weight = 0.5\n",
    "    last = parsed[0]\n",
    "    for v in parsed:\n",
    "        last = last * weight + (1 - weight) * v\n",
    "        parsed_smoothed.append(last)    \n",
    "\n",
    "    if metric != 'loss':\n",
    "        parsed_smoothed = [parsed_smoothed[i] * 100 for i in range(len(parsed_smoothed))]\n",
    "    \n",
    "    #label = f\"{trial}_{model_type}_{opt}_lr{lr:.1e}\"\n",
    "\n",
    "    if first_timestamp and last_timestamp:\n",
    "        time_diff = last_timestamp - first_timestamp\n",
    "\n",
    "    return parsed_smoothed, time_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "672d453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_interval(curves, confidence_level=0.95):\n",
    "    n = curves.shape[0]\n",
    "    mean_curve = np.mean(curves, axis=0)\n",
    "    std_curve = np.std(curves, axis=0, ddof=1)\n",
    "    stderr = std_curve / np.sqrt(n)\n",
    "    \n",
    "    t_crit = t.ppf((1 + confidence_level) / 2, df=n - 1)\n",
    "    \n",
    "    margin_of_error = t_crit * stderr\n",
    "    \n",
    "    lower_bound = mean_curve - margin_of_error\n",
    "    upper_bound = mean_curve + margin_of_error\n",
    "    \n",
    "    return lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b4617f",
   "metadata": {},
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd171b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/glusterfs/agurianova/architecture_change/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d19034",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_paths = {'Inception_V3':{'training':[f\"./inception/optuna_trial_{i}/logs.log\" for i in range(10)], \n",
    "                                'testing':[f'./inception/optuna_trial_{i}/test/happy.output.summary.csv' for i in range(10)]},\n",
    "                'EfficientNet_B3':{'training':[f\"./efficientnetb3/optuna_trial_{i}/logs.log\" for i in range(10)], \n",
    "                                    'testing':[f'./efficientnetb3/optuna_trial_{i}/test/happy.output.summary.csv' for i in range(10)]}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd87734",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5edcb20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['f1','precision','recall']\n",
    "metrics_features = {'f1':{'pattern':'xxxx','name':'f1_weighted'},\n",
    "                    'precision':{'pattern':r\"\\\\\\\\\",'name':'precision'},\n",
    "                    'recall':{'pattern':'////','name':'recall'}}\n",
    "\n",
    "parts_features = {'train':{'name':'training', 'steps_per_epoch':2778 / 5}, #(all steps / logging step)\n",
    "                  'tune':{'name':'validation','steps_per_epoch':1}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6613daf",
   "metadata": {},
   "source": [
    "### training-validation: loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c45a905",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    nrows = 1, ncols = 2,\n",
    "    figsize = (6,3),\n",
    "    sharex = True, sharey = False,\n",
    "    constrained_layout = True\n",
    ")\n",
    "\n",
    "configurations = [{'metric_key': 'loss', 'part': 'train'},\n",
    "                  {'metric_key': 'loss', 'part': 'tune'}]\n",
    "\n",
    "legend_handles = []\n",
    "legend_labels = []\n",
    "\n",
    "for ax, cfg in zip(axes, configurations):\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "\n",
    "        paths = result_paths[model]['training']\n",
    "        curves = []\n",
    "        for path in paths:\n",
    "            curve, label = parse_log(path, cfg['metric_key'], cfg['part'])\n",
    "            #curves.append(smooth_curve(curve,weight=0.4))\n",
    "            curves.append(curve)\n",
    "\n",
    "        curves = np.array(curves)\n",
    "        mean_curve = np.mean(curves, axis=0)\n",
    "        lower_bound, upper_bound = confidence_interval(curves, 0.95)\n",
    "\n",
    "        epochs = np.arange(1, curves.shape[1] + 1)\n",
    "\n",
    "        line, = ax.plot(epochs / parts_features[cfg['part']]['steps_per_epoch'], \n",
    "                mean_curve, \n",
    "                color=models_features[model]['color'][0], \n",
    "                linewidth=2)\n",
    "        ax.fill_between(epochs / parts_features[cfg['part']]['steps_per_epoch'], \n",
    "                        lower_bound, upper_bound, \n",
    "                        color=models_features[model]['color'][0], \n",
    "                        alpha=0.2)\n",
    "        \n",
    "        if ax == axes[0]:\n",
    "            legend_handles.append(line)\n",
    "            legend_labels.append(['Baseline (Inception_V3)', 'Alternative (EfficientNet-B3)'][i])\n",
    "\n",
    "    ax.set_title(f\"{parts_features[cfg['part']]['name'].upper()} {cfg['metric_key'].upper()}\", fontsize=13)\n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel(cfg['metric_key'].upper(), fontsize=10)\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax.set_ylim(0.58, 0.66)\n",
    "    ax.set_xticks(range(0,11,1))\n",
    "    \n",
    "fig.legend(\n",
    "    legend_handles, legend_labels,\n",
    "    title=\"Models\",\n",
    "    fontsize=10,\n",
    "    loc='center left',        \n",
    "    bbox_to_anchor=(1.02, 0.76))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dc67fe",
   "metadata": {},
   "source": [
    "### validation: metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e794d6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    nrows = 1, ncols = 3,\n",
    "    figsize = (8,3),\n",
    "    sharex = True, sharey = True,\n",
    "    constrained_layout = True\n",
    ")\n",
    "\n",
    "configurations = [{'metric_key': 'f1', 'part': 'tune'},\n",
    "                  {'metric_key': 'precision', 'part': 'tune'},\n",
    "                  {'metric_key': 'recall', 'part': 'tune'}]\n",
    "\n",
    "legend_handles = []\n",
    "legend_labels = []\n",
    "\n",
    "for ax, cfg in zip(axes, configurations):\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "\n",
    "        paths = result_paths[model]['training']\n",
    "        curves = []\n",
    "        for path in paths:\n",
    "            curve, label = parse_log(path, metrics_features[cfg['metric_key']]['name'], cfg['part'])\n",
    "            curves.append(curve)\n",
    "\n",
    "        curves = np.array(curves)\n",
    "        mean_curve = np.mean(curves, axis=0)\n",
    "        lower_bound, upper_bound = confidence_interval(curves, 0.95)\n",
    "\n",
    "        epochs = np.arange(1, curves.shape[1] + 1)\n",
    "        line, = ax.plot(epochs / parts_features[cfg['part']]['steps_per_epoch'], \n",
    "                mean_curve, \n",
    "                color=models_features[model]['color'][0], \n",
    "                linewidth=2)\n",
    "        ax.fill_between(epochs / parts_features[cfg['part']]['steps_per_epoch'], \n",
    "                        lower_bound, upper_bound, \n",
    "                        color=models_features[model]['color'][0], \n",
    "                        alpha=0.2)\n",
    "        \n",
    "        if ax == axes[0]:\n",
    "            legend_handles.append(line)\n",
    "            legend_labels.append(['Baseline (Inception_V3)', 'Alternative (EfficientNet-B3)'][i])\n",
    "\n",
    "    ax.set_title(f\"{parts_features[cfg['part']]['name'].upper()} {cfg['metric_key'].upper()}\", fontsize=13)\n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel(cfg['metric_key'].upper(), fontsize=10)\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax.set_xticks(range(0,11,1))\n",
    "    \n",
    "fig.legend(\n",
    "    legend_handles, legend_labels,\n",
    "    title=\"Models\",\n",
    "    fontsize=10,\n",
    "    loc='center left',        \n",
    "    bbox_to_anchor=(1.02, 0.76))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c02d9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_interval_list(data_list, confidence_level=0.95):\n",
    "    data = np.array(data_list) \n",
    "    n = len(data)\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data, ddof=1)\n",
    "    stderr = std / np.sqrt(n)\n",
    "    \n",
    "    t_crit = t.ppf((1 + confidence_level) / 2, df=n - 1)\n",
    "    margin_of_error = t_crit * stderr\n",
    "    \n",
    "    lower_bound = mean - margin_of_error\n",
    "    upper_bound = mean + margin_of_error\n",
    "    \n",
    "    return lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1e619936",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = {'Model':[],'Metric':[],'Value':[]}\n",
    "metrics = ['f1_weighted','precision','recall']\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "    for metric in metrics:\n",
    "\n",
    "        paths = result_paths[model]['training']\n",
    "\n",
    "        values = []\n",
    "        for path in paths:\n",
    "            parsed_values, _ = parse_log(path, f'{metric}', part='tune')\n",
    "            values.append(parsed_values[-1])\n",
    "\n",
    "        mean_value = round(np.mean(values), 2)\n",
    "        ci_l, ci_u = confidence_interval_list(values)\n",
    "        mean_ci = f'{round(mean_value,2)} (95% CI: {round(ci_l,2)}-{round(ci_u,2)})'\n",
    "\n",
    "        tab['Model'].append(model)\n",
    "        tab['Metric'].append(metric)\n",
    "        tab['Value'].append(mean_ci)\n",
    "\n",
    "df = pd.DataFrame(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f27f8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot(index='Model', columns='Metric', values='Value').reindex(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07a2200",
   "metadata": {},
   "source": [
    "### validation: metrics per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0ec4bceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['het','homalt','homref']\n",
    "classes_features = {'het':{'alleles':'0/1,','pattern':'//'},\n",
    "                    'homalt':{'alleles':'1/1,','pattern':'xx'},\n",
    "                    'homref':{'alleles':'0/0,','pattern':''}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a24a4b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = {'Model':[],'Metric':[],'Class':[],'Value':[]}\n",
    "metrics = ['f1', 'precision', 'recall']\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "    for metric in metrics:\n",
    "        \n",
    "        for class_ in classes:\n",
    "            \n",
    "            values = []\n",
    "            for path in result_paths[model]['training']:\n",
    "                parsed_values, _ = parse_log(path, f'{metric}_{class_}', part='tune')\n",
    "                values.append(parsed_values[-1])\n",
    "            mean_value = np.mean(values)\n",
    "\n",
    "            tab['Model'].append(model)\n",
    "            tab['Metric'].append(metric)\n",
    "            tab['Class'].append(class_)\n",
    "            tab['Value'].append(mean_value)\n",
    "\n",
    "df = pd.DataFrame(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7ae97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_index_order = ['homref', 'het', 'homalt']\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows = 1, ncols = 2,\n",
    "    figsize = (6,3),\n",
    "    sharex = True, sharey = False,\n",
    "    constrained_layout = True\n",
    ")\n",
    "\n",
    "configurations = [{'metric_key': 'f1_weighted', 'part': 'tune'},\n",
    "                  {'metric_key': 'precision', 'part': 'tune'},\n",
    "                  {'metric_key': 'recall', 'part': 'tune'}]\n",
    "\n",
    "# axes[0]\n",
    "pivot_df = df[df['Metric']=='f1'].pivot(index='Class', columns='Model', values='Value').reindex(custom_index_order)\n",
    "x = np.arange(len(classes))\n",
    "width = 0.4\n",
    "for i, model in enumerate(models):\n",
    "\n",
    "    bar_x_positions = x + i * width - width / 2\n",
    "    bar_y_values = pivot_df[model]\n",
    "    bar_colors = models_features[model]['color'] * len(bar_y_values)\n",
    "    bar_patterns = [metrics_features['f1']['pattern']] * len(bar_y_values)\n",
    "\n",
    "    bars = axes[0].bar(\n",
    "        bar_x_positions,\n",
    "        bar_y_values,\n",
    "        width,\n",
    "        color=bar_colors,\n",
    "        edgecolor='black'\n",
    "    )\n",
    "\n",
    "    for bar, pattern in zip(bars, bar_patterns):\n",
    "        bar.set_hatch(pattern)\n",
    "\n",
    "axes[0].set_ylabel('Value')\n",
    "axes[0].set_xlabel('Class')\n",
    "axes[0].set_title(f\"{parts_features['tune']['name'].upper()} {'F1'}\", fontsize=13)\n",
    "axes[0].set_ylim(90,98)\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels([f'{classes_features[i][\"alleles\"]}{i}' for i in pivot_df.index])\n",
    "\n",
    "# axes[1]\n",
    "width = 0.2\n",
    "side = -(width+0.01)\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "\n",
    "    pivot_df = df[(df['Metric']!='f1')&(df['Model']==model)].pivot(index='Class', columns='Metric', values='Value').reindex(custom_index_order) \n",
    "\n",
    "    for j, metric in enumerate(['precision','recall']):\n",
    "\n",
    "        bar_x_positions = (x + j * width - width / 2) + side\n",
    "        bar_y_values = pivot_df[metric]\n",
    "        bar_colors = models_features[model]['color'] * len(bar_y_values)\n",
    "        bar_patterns = [metrics_features[metric]['pattern']] * len(bar_y_values) \n",
    "\n",
    "        bars = axes[1].bar(\n",
    "            bar_x_positions,\n",
    "            bar_y_values,\n",
    "            width,\n",
    "            color=bar_colors,\n",
    "            edgecolor='black'\n",
    "        )\n",
    "        for bar, pattern in zip(bars, bar_patterns):\n",
    "            bar.set_hatch(pattern)\n",
    "\n",
    "    side = -side\n",
    "\n",
    "axes[1].set_ylabel('Value')\n",
    "axes[1].set_xlabel('Class')\n",
    "axes[1].set_title(f\"{parts_features['tune']['name'].upper()} {'PRECISION, RECALL'}\", fontsize=13)\n",
    "axes[1].set_ylim(90,98)\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels([f'{classes_features[i][\"alleles\"]}{i}' for i in pivot_df.index])\n",
    "\n",
    "# legend\n",
    "legend_handles = [Patch(facecolor=models_features['Inception_V3']['color'][0], hatch=\"\", edgecolor='black', label='Inception_V3'),\n",
    "                  Patch(facecolor=models_features['EfficientNet_B3']['color'][0], hatch=\"\", edgecolor='black', label='EfficientNet_B3'),\n",
    "                  Patch(facecolor='white', hatch=\"xx\", edgecolor='black', label='F1'),\n",
    "                  Patch(facecolor='white', hatch=metrics_features['precision']['pattern'], edgecolor='black', label='PRECISION'),\n",
    "                  Patch(facecolor='white', hatch=metrics_features['recall']['pattern'], edgecolor='black', label='RECALL')]\n",
    "legend_labels = ['Baseline (Inception_V3)','Alternative (EfficientNet_B3)','F1','PRECISION','RECALL']\n",
    "fig.legend(\n",
    "    legend_handles, legend_labels,\n",
    "    title=\"Models and Metrics\",\n",
    "    fontsize=10,\n",
    "    loc='center left',        \n",
    "    bbox_to_anchor=(1.03, 0.65))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6261e454",
   "metadata": {},
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04270545",
   "metadata": {},
   "source": [
    "### SNP/INDEL hap.py table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "133035c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = {'Type':[],'Model':[],'Metric':[],'Value':[]}\n",
    "metrics = ['METRIC.F1_Score','METRIC.Precision','METRIC.Recall']\n",
    "\n",
    "for type in ['SNP','INDEL']:\n",
    "\n",
    "    for model in models:\n",
    "        \n",
    "        for metric in metrics:\n",
    "\n",
    "                paths = result_paths[model]['testing']\n",
    "\n",
    "                values = []\n",
    "                for path in paths:\n",
    "                    df = pd.read_csv(path)\n",
    "                    df = df.loc[(df['Type'] == type) & (df['Filter'] == 'PASS')]\n",
    "                    value = df[metric].iloc[0]\n",
    "                    values.append(value)\n",
    "                values = np.array(values) * 100\n",
    "                \n",
    "                mean_value = np.mean(values)\n",
    "                ci_l, ci_u = confidence_interval_list(values)\n",
    "                mean_ci = f'{round(mean_value,2)} (95% CI: {round(ci_l,2)}-{round(ci_u,2)})'\n",
    "\n",
    "                tab['Type'].append(type)\n",
    "                tab['Model'].append(model)\n",
    "                tab['Metric'].append(metric)\n",
    "                tab['Value'].append(mean_ci)\n",
    "\n",
    "df = pd.DataFrame(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484db0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Type']=='SNP'].pivot(index='Model', columns='Metric', values='Value').reindex(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c4fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Type']=='INDEL'].pivot(index='Model', columns='Metric', values='Value').reindex(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c72ee93",
   "metadata": {},
   "source": [
    "### time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016aac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = {'Model':[],'Metric':[],'Value':[]}\n",
    "metrics = ['f1_weighted','precision','recall']\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "    paths = result_paths[model]['training']\n",
    "\n",
    "    values = []\n",
    "    for path in paths:\n",
    "        parsed_values, time = parse_log(path, f'{metric}', part='tune')\n",
    "        values.append(time)\n",
    "\n",
    "    mean_value = np.mean(values)\n",
    "    \n",
    "    tab['Model'].append(model)\n",
    "    tab['Metric'].append(metric)\n",
    "    tab['Value'].append(mean_value)\n",
    "\n",
    "df = pd.DataFrame(tab)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673c5aeb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
